{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import z_score_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from next_batch import LSTM_WINDOW_SIZE, INPUT_SIZE, PREDICTORS\n",
    "from next_batch import get_trainable_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lijinyang'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (2122, 10, 29)\n",
      "y_train.shape = (2122, 1)\n",
      "x_test.shape = (616, 10, 29)\n",
      "y_test.shape = (616, 1)\n"
     ]
    }
   ],
   "source": [
    "plt.ion()\n",
    "\n",
    "DATA_FILE = 'data.npz'\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    (x_train, y_train), (x_test, y_test), mean, std = get_trainable_data()\n",
    "    np.savez_compressed('data.npz', x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test,\n",
    "                        mean=mean, std=std)\n",
    "else:\n",
    "    d = np.load(DATA_FILE)\n",
    "    x_train = d['x_train']\n",
    "    y_train = d['y_train']\n",
    "    x_test = d['x_test']\n",
    "    y_test = d['y_test']\n",
    "    mean = d['mean']\n",
    "    std = d['std']\n",
    "\n",
    "print('x_train.shape =', x_train.shape)\n",
    "print('y_train.shape =', y_train.shape)\n",
    "\n",
    "print('x_test.shape =', x_test.shape)\n",
    "print('y_test.shape =', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTORS = PREDICTORS[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sigma',\n",
       " 'returns',\n",
       " 'Trend COMPUT',\n",
       " 'Trend CRCARD',\n",
       " 'Trend INVEST',\n",
       " 'Trend BNKRPT',\n",
       " 'Trend AIRTVL']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_20 (LSTM)               (None, 32)                7936      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 8,481.0\n",
      "Trainable params: 8,481\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Now we have 7/7 predictors.\n",
      "[0000] test = 2343.180, test_dummy = 35.730, train = 861.210, val = 2075.512.\n",
      "[0001] test = 2263.382, test_dummy = 35.730, train = 809.385, val = 1983.030.\n",
      "[0002] test = 2177.576, test_dummy = 35.730, train = 756.846, val = 1893.391.\n",
      "[0003] test = 2090.508, test_dummy = 35.730, train = 706.988, val = 1787.361.\n",
      "[0004] test = 2004.567, test_dummy = 35.730, train = 656.426, val = 1674.908.\n",
      "[0005] test = 1898.737, test_dummy = 35.730, train = 594.792, val = 1527.726.\n",
      "[0006] test = 1770.241, test_dummy = 35.730, train = 517.265, val = 1333.252.\n",
      "[0007] test = 1603.598, test_dummy = 35.730, train = 416.870, val = 1076.047.\n",
      "[0008] test = 1380.436, test_dummy = 35.730, train = 289.227, val = 731.810.\n",
      "[0009] test = 1064.821, test_dummy = 35.730, train = 149.236, val = 281.258.\n",
      "[0010] test = 936.606, test_dummy = 35.730, train = 68.477, val = 110.418.\n",
      "[0011] test = 951.345, test_dummy = 35.730, train = 59.082, val = 112.909.\n",
      "[0012] test = 933.588, test_dummy = 35.730, train = 55.830, val = 99.854.\n",
      "[0013] test = 937.084, test_dummy = 35.730, train = 53.617, val = 100.797.\n",
      "[0014] test = 940.288, test_dummy = 35.730, train = 51.084, val = 104.366.\n",
      "[0015] test = 928.334, test_dummy = 35.730, train = 49.510, val = 98.479.\n",
      "[0016] test = 912.910, test_dummy = 35.730, train = 48.315, val = 90.852.\n",
      "[0017] test = 901.147, test_dummy = 35.730, train = 47.178, val = 91.297.\n",
      "[0018] test = 895.518, test_dummy = 35.730, train = 46.171, val = 91.160.\n",
      "[0019] test = 882.742, test_dummy = 35.730, train = 45.330, val = 87.821.\n",
      "[0020] test = 876.786, test_dummy = 35.730, train = 44.649, val = 85.788.\n",
      "[0021] test = 874.855, test_dummy = 35.730, train = 43.903, val = 89.042.\n",
      "[0022] test = 866.611, test_dummy = 35.730, train = 43.441, val = 86.288.\n",
      "[0023] test = 860.091, test_dummy = 35.730, train = 43.016, val = 84.224.\n",
      "[0024] test = 849.571, test_dummy = 35.730, train = 43.016, val = 83.386.\n",
      "[0025] test = 839.202, test_dummy = 35.730, train = 42.340, val = 78.591.\n",
      "[0026] test = 841.074, test_dummy = 35.730, train = 41.999, val = 86.454.\n",
      "[0027] test = 831.628, test_dummy = 35.730, train = 41.762, val = 83.203.\n",
      "[0028] test = 826.858, test_dummy = 35.730, train = 41.522, val = 81.184.\n",
      "[0029] test = 836.860, test_dummy = 35.730, train = 41.300, val = 85.395.\n",
      "[0030] test = 835.140, test_dummy = 35.730, train = 41.188, val = 85.705.\n",
      "[0031] test = 823.570, test_dummy = 35.730, train = 40.901, val = 77.390.\n",
      "[0032] test = 819.517, test_dummy = 35.730, train = 40.822, val = 76.961.\n",
      "[0033] test = 818.817, test_dummy = 35.730, train = 40.455, val = 77.676.\n",
      "[0034] test = 809.047, test_dummy = 35.730, train = 40.266, val = 75.009.\n",
      "[0035] test = 801.838, test_dummy = 35.730, train = 40.238, val = 73.763.\n",
      "[0036] test = 802.504, test_dummy = 35.730, train = 40.484, val = 78.887.\n",
      "[0037] test = 799.481, test_dummy = 35.730, train = 39.911, val = 74.827.\n",
      "[0038] test = 801.724, test_dummy = 35.730, train = 39.663, val = 76.193.\n",
      "[0039] test = 808.471, test_dummy = 35.730, train = 39.580, val = 81.047.\n",
      "[0040] test = 795.091, test_dummy = 35.730, train = 39.458, val = 71.768.\n",
      "[0041] test = 815.441, test_dummy = 35.730, train = 39.906, val = 78.958.\n",
      "[0042] test = 807.075, test_dummy = 35.730, train = 39.371, val = 79.617.\n",
      "[0043] test = 788.884, test_dummy = 35.730, train = 39.220, val = 74.543.\n",
      "[0044] test = 787.553, test_dummy = 35.730, train = 38.998, val = 74.972.\n",
      "[0045] test = 778.281, test_dummy = 35.730, train = 38.928, val = 71.773.\n",
      "[0046] test = 778.814, test_dummy = 35.730, train = 38.813, val = 70.516.\n",
      "[0047] test = 776.265, test_dummy = 35.730, train = 39.092, val = 70.785.\n",
      "[0048] test = 781.265, test_dummy = 35.730, train = 38.585, val = 74.838.\n",
      "[0049] test = 789.837, test_dummy = 35.730, train = 38.558, val = 80.561.\n",
      "[0050] test = 774.079, test_dummy = 35.730, train = 38.409, val = 75.579.\n",
      "[0051] test = 768.164, test_dummy = 35.730, train = 38.377, val = 75.381.\n",
      "[0052] test = 759.658, test_dummy = 35.730, train = 38.287, val = 70.199.\n",
      "[0053] test = 759.167, test_dummy = 35.730, train = 38.134, val = 73.263.\n",
      "[0054] test = 748.294, test_dummy = 35.730, train = 38.103, val = 68.867.\n",
      "[0055] test = 741.048, test_dummy = 35.730, train = 38.176, val = 68.213.\n",
      "[0056] test = 748.364, test_dummy = 35.730, train = 37.997, val = 71.841.\n",
      "[0057] test = 755.492, test_dummy = 35.730, train = 38.021, val = 70.904.\n",
      "[0058] test = 747.624, test_dummy = 35.730, train = 37.841, val = 70.123.\n",
      "[0059] test = 744.200, test_dummy = 35.730, train = 37.746, val = 73.220.\n",
      "[0060] test = 732.416, test_dummy = 35.730, train = 37.558, val = 69.235.\n",
      "[0061] test = 722.450, test_dummy = 35.730, train = 37.554, val = 65.830.\n",
      "[0062] test = 720.506, test_dummy = 35.730, train = 37.452, val = 67.681.\n",
      "[0063] test = 709.967, test_dummy = 35.730, train = 37.615, val = 65.575.\n",
      "[0064] test = 714.981, test_dummy = 35.730, train = 37.524, val = 72.706.\n",
      "[0065] test = 705.502, test_dummy = 35.730, train = 37.633, val = 70.532.\n",
      "[0066] test = 693.860, test_dummy = 35.730, train = 37.211, val = 65.871.\n",
      "[0067] test = 690.699, test_dummy = 35.730, train = 37.214, val = 67.269.\n",
      "[0068] test = 687.855, test_dummy = 35.730, train = 37.085, val = 68.467.\n",
      "[0069] test = 670.209, test_dummy = 35.730, train = 37.209, val = 63.593.\n",
      "[0070] test = 680.822, test_dummy = 35.730, train = 37.027, val = 70.485.\n",
      "[0071] test = 667.409, test_dummy = 35.730, train = 37.037, val = 66.550.\n",
      "[0072] test = 667.894, test_dummy = 35.730, train = 36.872, val = 70.284.\n",
      "[0073] test = 648.985, test_dummy = 35.730, train = 36.782, val = 62.732.\n",
      "[0074] test = 648.863, test_dummy = 35.730, train = 36.798, val = 62.352.\n",
      "[0075] test = 655.866, test_dummy = 35.730, train = 36.675, val = 66.692.\n",
      "[0076] test = 641.511, test_dummy = 35.730, train = 36.666, val = 63.236.\n",
      "[0077] test = 637.273, test_dummy = 35.730, train = 36.611, val = 63.763.\n",
      "[0078] test = 622.507, test_dummy = 35.730, train = 36.513, val = 59.807.\n",
      "[0079] test = 649.781, test_dummy = 35.730, train = 36.660, val = 70.171.\n",
      "[0080] test = 645.440, test_dummy = 35.730, train = 36.571, val = 67.455.\n",
      "[0081] test = 638.943, test_dummy = 35.730, train = 36.690, val = 68.604.\n",
      "[0082] test = 622.717, test_dummy = 35.730, train = 36.368, val = 61.858.\n",
      "[0083] test = 628.509, test_dummy = 35.730, train = 36.368, val = 65.710.\n",
      "[0084] test = 623.852, test_dummy = 35.730, train = 36.394, val = 64.725.\n",
      "[0085] test = 617.733, test_dummy = 35.730, train = 36.170, val = 61.948.\n",
      "[0086] test = 618.438, test_dummy = 35.730, train = 36.293, val = 62.602.\n",
      "[0087] test = 615.076, test_dummy = 35.730, train = 36.294, val = 64.487.\n",
      "[0088] test = 606.664, test_dummy = 35.730, train = 36.092, val = 62.936.\n",
      "[0089] test = 602.308, test_dummy = 35.730, train = 36.231, val = 62.317.\n",
      "[0090] test = 599.021, test_dummy = 35.730, train = 36.012, val = 63.706.\n",
      "[0091] test = 592.259, test_dummy = 35.730, train = 35.990, val = 63.693.\n",
      "[0092] test = 584.954, test_dummy = 35.730, train = 36.015, val = 61.743.\n",
      "[0093] test = 569.740, test_dummy = 35.730, train = 36.234, val = 59.267.\n",
      "[0094] test = 567.141, test_dummy = 35.730, train = 35.860, val = 59.756.\n",
      "[0095] test = 571.628, test_dummy = 35.730, train = 35.885, val = 61.961.\n",
      "[0096] test = 581.520, test_dummy = 35.730, train = 36.039, val = 65.515.\n",
      "[0097] test = 548.447, test_dummy = 35.730, train = 35.757, val = 56.981.\n",
      "[0098] test = 576.865, test_dummy = 35.730, train = 35.883, val = 66.685.\n",
      "[0099] test = 585.877, test_dummy = 35.730, train = 36.118, val = 67.776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0100] test = 565.531, test_dummy = 35.730, train = 35.587, val = 64.705.\n",
      "[0101] test = 559.302, test_dummy = 35.730, train = 35.689, val = 63.282.\n",
      "[0102] test = 554.242, test_dummy = 35.730, train = 35.489, val = 63.739.\n",
      "[0103] test = 556.072, test_dummy = 35.730, train = 35.520, val = 65.470.\n",
      "[0104] test = 542.980, test_dummy = 35.730, train = 35.569, val = 62.081.\n",
      "[0105] test = 544.706, test_dummy = 35.730, train = 35.585, val = 63.139.\n",
      "[0106] test = 524.645, test_dummy = 35.730, train = 35.372, val = 56.907.\n",
      "[0107] test = 529.388, test_dummy = 35.730, train = 35.350, val = 60.065.\n",
      "[0108] test = 521.969, test_dummy = 35.730, train = 35.244, val = 58.920.\n",
      "[0109] test = 525.301, test_dummy = 35.730, train = 35.354, val = 59.353.\n",
      "[0110] test = 523.398, test_dummy = 35.730, train = 35.506, val = 58.546.\n",
      "[0111] test = 520.718, test_dummy = 35.730, train = 35.341, val = 59.400.\n",
      "[0112] test = 512.583, test_dummy = 35.730, train = 35.278, val = 57.374.\n",
      "[0113] test = 517.995, test_dummy = 35.730, train = 35.547, val = 58.962.\n",
      "[0114] test = 521.117, test_dummy = 35.730, train = 35.151, val = 59.732.\n",
      "[0115] test = 538.087, test_dummy = 35.730, train = 35.101, val = 65.036.\n",
      "[0116] test = 520.905, test_dummy = 35.730, train = 35.299, val = 61.014.\n",
      "[0117] test = 500.488, test_dummy = 35.730, train = 35.016, val = 56.083.\n",
      "[0118] test = 514.255, test_dummy = 35.730, train = 35.466, val = 60.685.\n",
      "[0119] test = 507.677, test_dummy = 35.730, train = 35.244, val = 59.194.\n",
      "[0120] test = 492.693, test_dummy = 35.730, train = 34.985, val = 56.290.\n",
      "[0121] test = 511.869, test_dummy = 35.730, train = 35.048, val = 63.115.\n",
      "[0122] test = 503.727, test_dummy = 35.730, train = 35.008, val = 60.297.\n",
      "[0123] test = 504.274, test_dummy = 35.730, train = 34.841, val = 61.349.\n",
      "[0124] test = 508.127, test_dummy = 35.730, train = 34.941, val = 63.413.\n",
      "[0125] test = 484.101, test_dummy = 35.730, train = 34.809, val = 55.745.\n",
      "[0126] test = 498.770, test_dummy = 35.730, train = 34.784, val = 62.861.\n",
      "[0127] test = 504.362, test_dummy = 35.730, train = 34.834, val = 66.441.\n",
      "[0128] test = 483.463, test_dummy = 35.730, train = 35.250, val = 61.085.\n",
      "[0129] test = 483.746, test_dummy = 35.730, train = 35.034, val = 61.712.\n",
      "[0130] test = 478.966, test_dummy = 35.730, train = 34.608, val = 60.765.\n",
      "[0131] test = 469.673, test_dummy = 35.730, train = 34.704, val = 58.238.\n",
      "[0132] test = 478.518, test_dummy = 35.730, train = 34.695, val = 61.853.\n",
      "[0133] test = 479.148, test_dummy = 35.730, train = 34.678, val = 63.750.\n",
      "[0134] test = 474.382, test_dummy = 35.730, train = 34.765, val = 61.947.\n",
      "[0135] test = 482.831, test_dummy = 35.730, train = 34.496, val = 64.564.\n",
      "[0136] test = 468.708, test_dummy = 35.730, train = 34.595, val = 59.788.\n",
      "[0137] test = 466.567, test_dummy = 35.730, train = 34.554, val = 59.019.\n",
      "[0138] test = 450.390, test_dummy = 35.730, train = 34.576, val = 54.975.\n",
      "[0139] test = 463.607, test_dummy = 35.730, train = 34.682, val = 59.180.\n",
      "[0140] test = 452.291, test_dummy = 35.730, train = 34.358, val = 56.986.\n",
      "[0141] test = 447.009, test_dummy = 35.730, train = 34.818, val = 58.544.\n",
      "[0142] test = 450.421, test_dummy = 35.730, train = 34.499, val = 60.100.\n",
      "[0143] test = 434.800, test_dummy = 35.730, train = 34.528, val = 53.490.\n",
      "[0144] test = 449.870, test_dummy = 35.730, train = 34.291, val = 58.177.\n",
      "[0145] test = 463.561, test_dummy = 35.730, train = 34.569, val = 64.480.\n",
      "[0146] test = 451.250, test_dummy = 35.730, train = 34.274, val = 57.851.\n",
      "[0147] test = 456.252, test_dummy = 35.730, train = 34.275, val = 59.034.\n",
      "[0148] test = 454.189, test_dummy = 35.730, train = 34.261, val = 59.656.\n",
      "[0149] test = 449.065, test_dummy = 35.730, train = 34.119, val = 57.096.\n",
      "[0150] test = 456.854, test_dummy = 35.730, train = 34.205, val = 61.620.\n",
      "[0151] test = 454.497, test_dummy = 35.730, train = 34.055, val = 60.479.\n",
      "[0152] test = 448.237, test_dummy = 35.730, train = 34.210, val = 59.322.\n",
      "[0153] test = 449.094, test_dummy = 35.730, train = 34.118, val = 60.574.\n",
      "[0154] test = 446.217, test_dummy = 35.730, train = 34.173, val = 60.840.\n",
      "[0155] test = 428.501, test_dummy = 35.730, train = 33.925, val = 54.865.\n",
      "[0156] test = 448.300, test_dummy = 35.730, train = 34.264, val = 61.774.\n",
      "[0157] test = 440.556, test_dummy = 35.730, train = 33.966, val = 58.755.\n",
      "[0158] test = 432.046, test_dummy = 35.730, train = 33.885, val = 55.984.\n",
      "[0159] test = 418.469, test_dummy = 35.730, train = 33.998, val = 52.998.\n",
      "[0160] test = 438.673, test_dummy = 35.730, train = 34.492, val = 57.467.\n",
      "[0161] test = 424.318, test_dummy = 35.730, train = 34.249, val = 52.872.\n",
      "[0162] test = 445.116, test_dummy = 35.730, train = 33.820, val = 60.410.\n",
      "[0163] test = 447.959, test_dummy = 35.730, train = 33.848, val = 61.536.\n",
      "[0164] test = 431.187, test_dummy = 35.730, train = 34.045, val = 55.705.\n",
      "[0165] test = 434.331, test_dummy = 35.730, train = 33.828, val = 55.931.\n",
      "[0166] test = 438.696, test_dummy = 35.730, train = 33.718, val = 58.126.\n",
      "[0167] test = 428.949, test_dummy = 35.730, train = 33.757, val = 55.570.\n",
      "[0168] test = 440.230, test_dummy = 35.730, train = 33.684, val = 59.026.\n",
      "[0169] test = 443.382, test_dummy = 35.730, train = 33.621, val = 59.778.\n",
      "[0170] test = 439.825, test_dummy = 35.730, train = 33.746, val = 59.063.\n",
      "[0171] test = 419.976, test_dummy = 35.730, train = 33.758, val = 53.380.\n",
      "[0172] test = 424.710, test_dummy = 35.730, train = 33.738, val = 54.878.\n",
      "[0173] test = 441.575, test_dummy = 35.730, train = 33.759, val = 60.233.\n",
      "[0174] test = 425.378, test_dummy = 35.730, train = 33.735, val = 54.844.\n",
      "[0175] test = 436.445, test_dummy = 35.730, train = 33.733, val = 58.536.\n",
      "[0176] test = 420.925, test_dummy = 35.730, train = 33.549, val = 54.901.\n",
      "[0177] test = 408.187, test_dummy = 35.730, train = 33.591, val = 51.924.\n",
      "[0178] test = 411.739, test_dummy = 35.730, train = 36.516, val = 53.342.\n",
      "[0179] test = 438.377, test_dummy = 35.730, train = 33.809, val = 61.778.\n",
      "[0180] test = 416.761, test_dummy = 35.730, train = 33.590, val = 54.230.\n",
      "[0181] test = 414.982, test_dummy = 35.730, train = 33.492, val = 53.574.\n",
      "[0182] test = 422.139, test_dummy = 35.730, train = 33.441, val = 55.453.\n",
      "[0183] test = 424.502, test_dummy = 35.730, train = 33.347, val = 56.289.\n",
      "[0184] test = 418.583, test_dummy = 35.730, train = 33.597, val = 55.413.\n",
      "[0185] test = 414.897, test_dummy = 35.730, train = 33.372, val = 56.415.\n",
      "[0186] test = 423.594, test_dummy = 35.730, train = 33.347, val = 57.925.\n",
      "[0187] test = 424.372, test_dummy = 35.730, train = 33.313, val = 58.685.\n",
      "[0188] test = 420.564, test_dummy = 35.730, train = 33.365, val = 57.905.\n",
      "[0189] test = 410.610, test_dummy = 35.730, train = 33.307, val = 54.400.\n",
      "[0190] test = 406.081, test_dummy = 35.730, train = 33.195, val = 53.959.\n",
      "[0191] test = 410.473, test_dummy = 35.730, train = 33.275, val = 54.777.\n",
      "[0192] test = 406.002, test_dummy = 35.730, train = 33.209, val = 54.377.\n",
      "[0193] test = 411.099, test_dummy = 35.730, train = 33.305, val = 56.379.\n",
      "[0194] test = 407.695, test_dummy = 35.730, train = 33.144, val = 56.145.\n",
      "[0195] test = 406.372, test_dummy = 35.730, train = 33.256, val = 55.663.\n",
      "[0196] test = 403.230, test_dummy = 35.730, train = 33.103, val = 54.298.\n",
      "[0197] test = 402.529, test_dummy = 35.730, train = 33.316, val = 55.110.\n",
      "[0198] test = 406.626, test_dummy = 35.730, train = 33.159, val = 56.749.\n",
      "[0199] test = 393.796, test_dummy = 35.730, train = 33.144, val = 52.136.\n",
      "[0200] test = 393.167, test_dummy = 35.730, train = 33.270, val = 52.710.\n",
      "[0201] test = 415.814, test_dummy = 35.730, train = 33.031, val = 59.344.\n",
      "[0202] test = 410.685, test_dummy = 35.730, train = 33.309, val = 58.958.\n",
      "[0203] test = 401.205, test_dummy = 35.730, train = 32.987, val = 55.375.\n",
      "[0204] test = 396.101, test_dummy = 35.730, train = 33.128, val = 56.465.\n",
      "[0205] test = 397.311, test_dummy = 35.730, train = 33.144, val = 56.478.\n",
      "[0206] test = 405.228, test_dummy = 35.730, train = 33.031, val = 61.211.\n",
      "[0207] test = 390.457, test_dummy = 35.730, train = 33.280, val = 55.325.\n",
      "[0208] test = 388.641, test_dummy = 35.730, train = 32.961, val = 55.960.\n",
      "[0209] test = 391.146, test_dummy = 35.730, train = 32.971, val = 56.288.\n",
      "[0210] test = 389.216, test_dummy = 35.730, train = 32.911, val = 55.403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0211] test = 380.968, test_dummy = 35.730, train = 32.838, val = 51.977.\n",
      "[0212] test = 382.078, test_dummy = 35.730, train = 32.901, val = 52.492.\n",
      "[0213] test = 398.861, test_dummy = 35.730, train = 33.074, val = 58.675.\n",
      "[0214] test = 395.411, test_dummy = 35.730, train = 33.087, val = 57.598.\n",
      "[0215] test = 389.733, test_dummy = 35.730, train = 32.831, val = 54.683.\n",
      "[0216] test = 398.626, test_dummy = 35.730, train = 33.090, val = 57.325.\n",
      "[0217] test = 394.943, test_dummy = 35.730, train = 32.793, val = 56.498.\n",
      "[0218] test = 376.140, test_dummy = 35.730, train = 32.821, val = 50.847.\n",
      "[0219] test = 376.723, test_dummy = 35.730, train = 32.802, val = 51.434.\n",
      "[0220] test = 393.714, test_dummy = 35.730, train = 32.989, val = 57.859.\n",
      "[0221] test = 386.159, test_dummy = 35.730, train = 32.736, val = 53.498.\n",
      "[0222] test = 390.901, test_dummy = 35.730, train = 32.649, val = 53.561.\n",
      "[0223] test = 404.388, test_dummy = 35.730, train = 32.782, val = 57.633.\n",
      "[0224] test = 405.413, test_dummy = 35.730, train = 32.760, val = 57.866.\n",
      "[0225] test = 405.143, test_dummy = 35.730, train = 32.642, val = 56.855.\n",
      "[0226] test = 394.133, test_dummy = 35.730, train = 32.660, val = 52.131.\n",
      "[0227] test = 418.948, test_dummy = 35.730, train = 32.810, val = 62.203.\n",
      "[0228] test = 397.827, test_dummy = 35.730, train = 33.779, val = 55.283.\n",
      "[0229] test = 398.499, test_dummy = 35.730, train = 32.603, val = 56.332.\n",
      "[0230] test = 382.631, test_dummy = 35.730, train = 32.682, val = 51.161.\n",
      "[0231] test = 395.926, test_dummy = 35.730, train = 32.577, val = 56.407.\n",
      "[0232] test = 391.044, test_dummy = 35.730, train = 32.488, val = 54.506.\n",
      "[0233] test = 401.130, test_dummy = 35.730, train = 32.646, val = 56.943.\n",
      "[0234] test = 389.119, test_dummy = 35.730, train = 32.393, val = 52.526.\n",
      "[0235] test = 398.673, test_dummy = 35.730, train = 32.630, val = 56.855.\n",
      "[0236] test = 385.370, test_dummy = 35.730, train = 33.613, val = 52.759.\n",
      "[0237] test = 397.760, test_dummy = 35.730, train = 32.453, val = 55.962.\n",
      "[0238] test = 403.381, test_dummy = 35.730, train = 32.384, val = 57.780.\n",
      "[0239] test = 395.979, test_dummy = 35.730, train = 32.598, val = 56.751.\n",
      "[0240] test = 391.680, test_dummy = 35.730, train = 32.434, val = 55.379.\n",
      "[0241] test = 392.059, test_dummy = 35.730, train = 32.581, val = 56.025.\n",
      "[0242] test = 392.621, test_dummy = 35.730, train = 32.324, val = 55.643.\n",
      "[0243] test = 395.584, test_dummy = 35.730, train = 32.328, val = 56.034.\n",
      "[0244] test = 385.841, test_dummy = 35.730, train = 32.403, val = 52.978.\n",
      "[0245] test = 388.518, test_dummy = 35.730, train = 32.291, val = 54.841.\n",
      "[0246] test = 379.325, test_dummy = 35.730, train = 32.936, val = 53.404.\n",
      "[0247] test = 390.435, test_dummy = 35.730, train = 32.263, val = 56.979.\n",
      "[0248] test = 381.707, test_dummy = 35.730, train = 32.333, val = 53.528.\n",
      "[0249] test = 401.500, test_dummy = 35.730, train = 32.265, val = 60.864.\n",
      "[0250] test = 393.510, test_dummy = 35.730, train = 32.398, val = 57.537.\n",
      "[0251] test = 392.029, test_dummy = 35.730, train = 32.375, val = 55.591.\n",
      "[0252] test = 385.796, test_dummy = 35.730, train = 32.327, val = 53.130.\n",
      "[0253] test = 380.993, test_dummy = 35.730, train = 32.338, val = 52.573.\n",
      "[0254] test = 389.233, test_dummy = 35.730, train = 32.625, val = 55.746.\n",
      "[0255] test = 375.868, test_dummy = 35.730, train = 32.201, val = 51.078.\n",
      "[0256] test = 391.804, test_dummy = 35.730, train = 32.110, val = 56.174.\n",
      "[0257] test = 392.218, test_dummy = 35.730, train = 32.172, val = 55.749.\n",
      "[0258] test = 389.955, test_dummy = 35.730, train = 32.163, val = 54.963.\n",
      "[0259] test = 387.582, test_dummy = 35.730, train = 32.086, val = 53.232.\n",
      "[0260] test = 381.025, test_dummy = 35.730, train = 32.051, val = 52.805.\n",
      "[0261] test = 381.417, test_dummy = 35.730, train = 32.067, val = 52.521.\n",
      "[0262] test = 386.873, test_dummy = 35.730, train = 32.139, val = 54.473.\n",
      "[0263] test = 386.699, test_dummy = 35.730, train = 32.049, val = 54.533.\n",
      "[0264] test = 385.565, test_dummy = 35.730, train = 32.048, val = 53.999.\n",
      "[0265] test = 395.311, test_dummy = 35.730, train = 32.010, val = 57.728.\n",
      "[0266] test = 387.011, test_dummy = 35.730, train = 32.529, val = 54.733.\n",
      "[0267] test = 397.100, test_dummy = 35.730, train = 32.075, val = 60.309.\n",
      "[0268] test = 390.559, test_dummy = 35.730, train = 31.977, val = 55.896.\n",
      "[0269] test = 390.678, test_dummy = 35.730, train = 31.981, val = 55.712.\n",
      "[0270] test = 383.738, test_dummy = 35.730, train = 31.905, val = 52.193.\n",
      "[0271] test = 403.398, test_dummy = 35.730, train = 32.174, val = 59.448.\n",
      "[0272] test = 390.515, test_dummy = 35.730, train = 32.016, val = 54.917.\n",
      "[0273] test = 392.967, test_dummy = 35.730, train = 31.900, val = 55.941.\n",
      "[0274] test = 383.731, test_dummy = 35.730, train = 31.819, val = 53.156.\n",
      "[0275] test = 379.799, test_dummy = 35.730, train = 32.369, val = 55.375.\n",
      "[0276] test = 376.019, test_dummy = 35.730, train = 31.927, val = 52.940.\n",
      "[0277] test = 374.134, test_dummy = 35.730, train = 31.844, val = 51.896.\n",
      "[0278] test = 383.226, test_dummy = 35.730, train = 31.871, val = 55.639.\n",
      "[0279] test = 368.057, test_dummy = 35.730, train = 31.733, val = 51.107.\n",
      "[0280] test = 378.093, test_dummy = 35.730, train = 31.815, val = 54.064.\n",
      "[0281] test = 382.940, test_dummy = 35.730, train = 31.839, val = 55.413.\n",
      "[0282] test = 385.296, test_dummy = 35.730, train = 32.120, val = 55.531.\n",
      "[0283] test = 385.830, test_dummy = 35.730, train = 31.933, val = 53.451.\n",
      "[0284] test = 384.018, test_dummy = 35.730, train = 31.672, val = 52.642.\n",
      "[0285] test = 406.581, test_dummy = 35.730, train = 31.868, val = 63.604.\n",
      "[0286] test = 382.655, test_dummy = 35.730, train = 31.991, val = 52.332.\n",
      "[0287] test = 391.981, test_dummy = 35.730, train = 31.771, val = 56.265.\n",
      "[0288] test = 389.360, test_dummy = 35.730, train = 31.705, val = 56.318.\n",
      "[0289] test = 379.692, test_dummy = 35.730, train = 31.786, val = 52.978.\n",
      "[0290] test = 402.358, test_dummy = 35.730, train = 31.715, val = 62.460.\n",
      "[0291] test = 390.306, test_dummy = 35.730, train = 32.055, val = 56.502.\n",
      "[0292] test = 377.865, test_dummy = 35.730, train = 31.709, val = 51.046.\n",
      "[0293] test = 392.666, test_dummy = 35.730, train = 31.531, val = 55.503.\n",
      "[0294] test = 385.051, test_dummy = 35.730, train = 31.585, val = 53.225.\n",
      "[0295] test = 392.077, test_dummy = 35.730, train = 31.902, val = 55.764.\n",
      "[0296] test = 385.116, test_dummy = 35.730, train = 31.584, val = 52.478.\n",
      "[0297] test = 388.277, test_dummy = 35.730, train = 31.615, val = 53.178.\n",
      "[0298] test = 398.332, test_dummy = 35.730, train = 31.638, val = 57.621.\n",
      "[0299] test = 390.341, test_dummy = 35.730, train = 31.477, val = 53.439.\n",
      "[0300] test = 400.972, test_dummy = 35.730, train = 31.402, val = 56.449.\n",
      "[0301] test = 397.561, test_dummy = 35.730, train = 31.537, val = 56.294.\n",
      "[0302] test = 404.682, test_dummy = 35.730, train = 31.516, val = 57.625.\n",
      "[0303] test = 401.605, test_dummy = 35.730, train = 31.617, val = 56.905.\n",
      "[0304] test = 378.854, test_dummy = 35.730, train = 32.947, val = 50.660.\n",
      "[0305] test = 395.010, test_dummy = 35.730, train = 31.439, val = 55.445.\n",
      "[0306] test = 391.306, test_dummy = 35.730, train = 31.497, val = 54.706.\n",
      "[0307] test = 403.920, test_dummy = 35.730, train = 31.523, val = 60.145.\n",
      "[0308] test = 388.524, test_dummy = 35.730, train = 31.591, val = 55.299.\n",
      "[0309] test = 388.006, test_dummy = 35.730, train = 31.531, val = 55.099.\n",
      "[0310] test = 382.755, test_dummy = 35.730, train = 31.436, val = 52.125.\n",
      "[0311] test = 392.752, test_dummy = 35.730, train = 31.521, val = 55.848.\n",
      "[0312] test = 385.779, test_dummy = 35.730, train = 31.402, val = 53.215.\n",
      "[0313] test = 384.954, test_dummy = 35.730, train = 31.395, val = 52.582.\n",
      "[0314] test = 395.797, test_dummy = 35.730, train = 31.252, val = 56.248.\n",
      "[0315] test = 393.399, test_dummy = 35.730, train = 31.611, val = 56.915.\n",
      "[0316] test = 395.905, test_dummy = 35.730, train = 32.643, val = 58.136.\n",
      "[0317] test = 392.091, test_dummy = 35.730, train = 31.387, val = 56.540.\n",
      "[0318] test = 404.730, test_dummy = 35.730, train = 31.606, val = 63.403.\n",
      "[0319] test = 396.268, test_dummy = 35.730, train = 31.442, val = 58.067.\n",
      "[0320] test = 388.133, test_dummy = 35.730, train = 31.403, val = 54.760.\n",
      "[0321] test = 392.468, test_dummy = 35.730, train = 31.433, val = 56.385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0322] test = 399.834, test_dummy = 35.730, train = 31.248, val = 59.638.\n",
      "[0323] test = 400.787, test_dummy = 35.730, train = 31.241, val = 60.264.\n",
      "[0324] test = 393.807, test_dummy = 35.730, train = 31.259, val = 58.522.\n",
      "[0325] test = 391.926, test_dummy = 35.730, train = 31.442, val = 57.761.\n",
      "[0326] test = 380.189, test_dummy = 35.730, train = 31.572, val = 53.981.\n",
      "[0327] test = 387.760, test_dummy = 35.730, train = 31.123, val = 56.307.\n",
      "[0328] test = 385.194, test_dummy = 35.730, train = 31.357, val = 53.377.\n",
      "[0329] test = 388.367, test_dummy = 35.730, train = 31.178, val = 54.172.\n",
      "[0330] test = 395.986, test_dummy = 35.730, train = 31.147, val = 57.612.\n",
      "[0331] test = 386.870, test_dummy = 35.730, train = 31.175, val = 56.215.\n",
      "[0332] test = 380.686, test_dummy = 35.730, train = 31.527, val = 53.461.\n",
      "[0333] test = 394.227, test_dummy = 35.730, train = 31.051, val = 58.522.\n",
      "[0334] test = 370.791, test_dummy = 35.730, train = 31.182, val = 49.879.\n",
      "[0335] test = 389.076, test_dummy = 35.730, train = 31.295, val = 55.957.\n",
      "[0336] test = 390.014, test_dummy = 35.730, train = 31.231, val = 56.503.\n",
      "[0337] test = 386.145, test_dummy = 35.730, train = 31.226, val = 55.781.\n",
      "[0338] test = 392.969, test_dummy = 35.730, train = 31.146, val = 56.759.\n",
      "[0339] test = 380.806, test_dummy = 35.730, train = 31.045, val = 53.105.\n",
      "[0340] test = 385.722, test_dummy = 35.730, train = 31.021, val = 55.230.\n",
      "[0341] test = 380.738, test_dummy = 35.730, train = 31.025, val = 52.459.\n",
      "[0342] test = 390.161, test_dummy = 35.730, train = 31.015, val = 56.206.\n",
      "[0343] test = 381.711, test_dummy = 35.730, train = 31.158, val = 54.248.\n",
      "[0344] test = 371.863, test_dummy = 35.730, train = 31.713, val = 51.767.\n",
      "[0345] test = 388.533, test_dummy = 35.730, train = 31.128, val = 57.810.\n",
      "[0346] test = 381.691, test_dummy = 35.730, train = 31.022, val = 54.136.\n",
      "[0347] test = 374.137, test_dummy = 35.730, train = 31.047, val = 51.444.\n",
      "[0348] test = 395.664, test_dummy = 35.730, train = 31.049, val = 60.721.\n",
      "[0349] test = 389.509, test_dummy = 35.730, train = 31.058, val = 57.586.\n",
      "[0350] test = 390.524, test_dummy = 35.730, train = 31.080, val = 57.122.\n",
      "[0351] test = 380.650, test_dummy = 35.730, train = 31.086, val = 52.696.\n",
      "[0352] test = 375.619, test_dummy = 35.730, train = 30.883, val = 51.724.\n",
      "[0353] test = 387.918, test_dummy = 35.730, train = 30.996, val = 58.404.\n",
      "[0354] test = 379.996, test_dummy = 35.730, train = 30.966, val = 52.953.\n",
      "[0355] test = 398.410, test_dummy = 35.730, train = 31.031, val = 61.734.\n",
      "[0356] test = 384.836, test_dummy = 35.730, train = 31.237, val = 55.094.\n",
      "[0357] test = 376.657, test_dummy = 35.730, train = 30.997, val = 51.777.\n",
      "[0358] test = 373.339, test_dummy = 35.730, train = 30.899, val = 51.110.\n",
      "[0359] test = 385.950, test_dummy = 35.730, train = 30.982, val = 54.157.\n",
      "[0360] test = 384.355, test_dummy = 35.730, train = 30.826, val = 53.125.\n",
      "[0361] test = 391.433, test_dummy = 35.730, train = 30.889, val = 57.178.\n",
      "[0362] test = 384.329, test_dummy = 35.730, train = 31.386, val = 54.975.\n",
      "[0363] test = 377.636, test_dummy = 35.730, train = 30.764, val = 52.589.\n",
      "[0364] test = 377.608, test_dummy = 35.730, train = 30.849, val = 52.206.\n",
      "[0365] test = 375.159, test_dummy = 35.730, train = 30.815, val = 51.312.\n",
      "[0366] test = 392.600, test_dummy = 35.730, train = 30.937, val = 56.060.\n",
      "[0367] test = 388.555, test_dummy = 35.730, train = 30.812, val = 56.469.\n",
      "[0368] test = 376.497, test_dummy = 35.730, train = 31.131, val = 51.298.\n",
      "[0369] test = 383.500, test_dummy = 35.730, train = 30.744, val = 54.051.\n",
      "[0370] test = 379.597, test_dummy = 35.730, train = 30.812, val = 52.605.\n",
      "[0371] test = 385.253, test_dummy = 35.730, train = 30.767, val = 54.795.\n",
      "[0372] test = 384.596, test_dummy = 35.730, train = 30.658, val = 54.399.\n",
      "[0373] test = 385.858, test_dummy = 35.730, train = 31.005, val = 55.023.\n",
      "[0374] test = 386.562, test_dummy = 35.730, train = 30.719, val = 55.956.\n",
      "[0375] test = 386.000, test_dummy = 35.730, train = 30.781, val = 54.866.\n",
      "[0376] test = 372.549, test_dummy = 35.730, train = 30.649, val = 50.904.\n",
      "[0377] test = 387.972, test_dummy = 35.730, train = 30.935, val = 60.207.\n",
      "[0378] test = 390.976, test_dummy = 35.730, train = 30.653, val = 63.051.\n",
      "[0379] test = 371.663, test_dummy = 35.730, train = 30.678, val = 52.660.\n",
      "[0380] test = 375.066, test_dummy = 35.730, train = 30.574, val = 53.350.\n",
      "[0381] test = 388.864, test_dummy = 35.730, train = 30.551, val = 60.890.\n",
      "[0382] test = 371.273, test_dummy = 35.730, train = 30.802, val = 53.322.\n",
      "[0383] test = 365.094, test_dummy = 35.730, train = 30.681, val = 51.039.\n",
      "[0384] test = 383.698, test_dummy = 35.730, train = 30.551, val = 59.576.\n",
      "[0385] test = 362.415, test_dummy = 35.730, train = 30.674, val = 51.208.\n",
      "[0386] test = 380.486, test_dummy = 35.730, train = 30.488, val = 57.628.\n",
      "[0387] test = 372.564, test_dummy = 35.730, train = 30.643, val = 54.640.\n",
      "[0388] test = 373.580, test_dummy = 35.730, train = 30.422, val = 54.250.\n",
      "[0389] test = 365.299, test_dummy = 35.730, train = 30.545, val = 51.378.\n",
      "[0390] test = 374.537, test_dummy = 35.730, train = 30.537, val = 53.298.\n",
      "[0391] test = 381.063, test_dummy = 35.730, train = 30.574, val = 55.494.\n",
      "[0392] test = 370.845, test_dummy = 35.730, train = 30.475, val = 51.929.\n",
      "[0393] test = 397.271, test_dummy = 35.730, train = 30.901, val = 60.643.\n",
      "[0394] test = 383.883, test_dummy = 35.730, train = 30.579, val = 54.606.\n",
      "[0395] test = 383.282, test_dummy = 35.730, train = 30.585, val = 53.135.\n",
      "[0396] test = 382.540, test_dummy = 35.730, train = 30.454, val = 54.541.\n",
      "[0397] test = 382.989, test_dummy = 35.730, train = 30.414, val = 55.169.\n",
      "[0398] test = 379.535, test_dummy = 35.730, train = 30.524, val = 54.542.\n",
      "[0399] test = 377.512, test_dummy = 35.730, train = 30.380, val = 54.553.\n",
      "[0400] test = 379.289, test_dummy = 35.730, train = 30.447, val = 55.376.\n",
      "[0401] test = 369.427, test_dummy = 35.730, train = 30.279, val = 51.640.\n",
      "[0402] test = 391.006, test_dummy = 35.730, train = 30.623, val = 62.139.\n",
      "[0403] test = 376.732, test_dummy = 35.730, train = 30.680, val = 55.925.\n",
      "[0404] test = 367.438, test_dummy = 35.730, train = 30.682, val = 52.129.\n",
      "[0405] test = 371.441, test_dummy = 35.730, train = 30.282, val = 52.667.\n",
      "[0406] test = 375.214, test_dummy = 35.730, train = 30.319, val = 53.585.\n",
      "[0407] test = 385.266, test_dummy = 35.730, train = 30.393, val = 55.313.\n",
      "[0408] test = 379.191, test_dummy = 35.730, train = 30.427, val = 53.335.\n",
      "[0409] test = 384.594, test_dummy = 35.730, train = 30.311, val = 56.247.\n",
      "[0410] test = 383.059, test_dummy = 35.730, train = 30.430, val = 55.927.\n",
      "[0411] test = 376.872, test_dummy = 35.730, train = 30.315, val = 53.905.\n",
      "[0412] test = 368.537, test_dummy = 35.730, train = 30.338, val = 50.674.\n",
      "[0413] test = 380.506, test_dummy = 35.730, train = 30.490, val = 54.721.\n",
      "[0414] test = 391.127, test_dummy = 35.730, train = 30.230, val = 58.735.\n",
      "[0415] test = 378.433, test_dummy = 35.730, train = 30.281, val = 53.890.\n",
      "[0416] test = 384.043, test_dummy = 35.730, train = 30.223, val = 56.733.\n",
      "[0417] test = 383.051, test_dummy = 35.730, train = 30.239, val = 54.728.\n",
      "[0418] test = 374.043, test_dummy = 35.730, train = 30.156, val = 51.648.\n",
      "[0419] test = 375.722, test_dummy = 35.730, train = 30.357, val = 53.168.\n",
      "[0420] test = 365.695, test_dummy = 35.730, train = 30.295, val = 50.038.\n",
      "[0421] test = 388.194, test_dummy = 35.730, train = 30.178, val = 56.763.\n",
      "[0422] test = 392.907, test_dummy = 35.730, train = 30.236, val = 58.658.\n",
      "[0423] test = 382.262, test_dummy = 35.730, train = 30.313, val = 52.767.\n",
      "[0424] test = 390.728, test_dummy = 35.730, train = 30.395, val = 56.994.\n",
      "[0425] test = 379.419, test_dummy = 35.730, train = 30.251, val = 53.373.\n",
      "[0426] test = 401.768, test_dummy = 35.730, train = 30.163, val = 64.310.\n",
      "[0427] test = 385.459, test_dummy = 35.730, train = 30.320, val = 55.211.\n",
      "[0428] test = 384.975, test_dummy = 35.730, train = 30.027, val = 55.842.\n",
      "[0429] test = 379.613, test_dummy = 35.730, train = 30.102, val = 53.496.\n",
      "[0430] test = 384.655, test_dummy = 35.730, train = 30.156, val = 56.011.\n",
      "[0431] test = 392.182, test_dummy = 35.730, train = 30.049, val = 59.340.\n",
      "[0432] test = 377.821, test_dummy = 35.730, train = 30.212, val = 52.782.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0433] test = 375.138, test_dummy = 35.730, train = 30.043, val = 52.497.\n",
      "[0434] test = 380.798, test_dummy = 35.730, train = 30.123, val = 54.448.\n",
      "[0435] test = 392.069, test_dummy = 35.730, train = 30.166, val = 60.604.\n",
      "[0436] test = 378.439, test_dummy = 35.730, train = 30.352, val = 54.420.\n",
      "[0437] test = 375.744, test_dummy = 35.730, train = 30.383, val = 53.743.\n",
      "[0438] test = 374.993, test_dummy = 35.730, train = 30.214, val = 53.888.\n",
      "[0439] test = 377.321, test_dummy = 35.730, train = 29.989, val = 54.727.\n",
      "[0440] test = 360.602, test_dummy = 35.730, train = 30.305, val = 50.127.\n",
      "[0441] test = 386.569, test_dummy = 35.730, train = 30.108, val = 58.735.\n",
      "[0442] test = 388.276, test_dummy = 35.730, train = 29.927, val = 58.302.\n",
      "[0443] test = 382.797, test_dummy = 35.730, train = 30.498, val = 56.336.\n",
      "[0444] test = 371.825, test_dummy = 35.730, train = 30.214, val = 52.254.\n",
      "[0445] test = 390.286, test_dummy = 35.730, train = 30.156, val = 59.352.\n",
      "[0446] test = 383.329, test_dummy = 35.730, train = 29.962, val = 54.688.\n",
      "[0447] test = 382.671, test_dummy = 35.730, train = 30.142, val = 54.630.\n",
      "[0448] test = 382.268, test_dummy = 35.730, train = 30.213, val = 53.801.\n",
      "[0449] test = 384.281, test_dummy = 35.730, train = 30.186, val = 55.284.\n",
      "[0450] test = 389.698, test_dummy = 35.730, train = 29.902, val = 56.740.\n",
      "[0451] test = 398.749, test_dummy = 35.730, train = 29.788, val = 64.089.\n",
      "[0452] test = 385.706, test_dummy = 35.730, train = 29.940, val = 56.502.\n",
      "[0453] test = 377.927, test_dummy = 35.730, train = 29.980, val = 55.178.\n",
      "[0454] test = 382.005, test_dummy = 35.730, train = 29.946, val = 56.025.\n",
      "[0455] test = 379.170, test_dummy = 35.730, train = 30.129, val = 54.742.\n",
      "[0456] test = 386.636, test_dummy = 35.730, train = 29.905, val = 59.105.\n",
      "[0457] test = 369.239, test_dummy = 35.730, train = 30.600, val = 52.426.\n",
      "[0458] test = 377.115, test_dummy = 35.730, train = 29.830, val = 54.485.\n",
      "[0459] test = 381.570, test_dummy = 35.730, train = 29.774, val = 55.167.\n",
      "[0460] test = 378.635, test_dummy = 35.730, train = 29.990, val = 54.730.\n",
      "[0461] test = 384.929, test_dummy = 35.730, train = 30.080, val = 58.517.\n",
      "[0462] test = 374.670, test_dummy = 35.730, train = 29.842, val = 53.223.\n",
      "[0463] test = 374.003, test_dummy = 35.730, train = 30.007, val = 52.965.\n",
      "[0464] test = 376.276, test_dummy = 35.730, train = 29.950, val = 54.700.\n",
      "[0465] test = 375.572, test_dummy = 35.730, train = 29.879, val = 55.659.\n",
      "[0466] test = 348.501, test_dummy = 35.730, train = 30.249, val = 48.216.\n",
      "[0467] test = 363.631, test_dummy = 35.730, train = 29.905, val = 52.271.\n",
      "[0468] test = 359.890, test_dummy = 35.730, train = 29.806, val = 50.421.\n",
      "[0469] test = 380.174, test_dummy = 35.730, train = 29.818, val = 56.819.\n",
      "[0470] test = 370.307, test_dummy = 35.730, train = 29.915, val = 53.131.\n",
      "[0471] test = 366.959, test_dummy = 35.730, train = 31.034, val = 51.738.\n",
      "[0472] test = 366.278, test_dummy = 35.730, train = 29.671, val = 52.086.\n",
      "[0473] test = 367.315, test_dummy = 35.730, train = 29.748, val = 53.288.\n",
      "[0474] test = 364.472, test_dummy = 35.730, train = 29.742, val = 52.076.\n",
      "[0475] test = 366.805, test_dummy = 35.730, train = 30.834, val = 52.884.\n",
      "[0476] test = 375.503, test_dummy = 35.730, train = 29.830, val = 56.170.\n",
      "[0477] test = 375.893, test_dummy = 35.730, train = 29.791, val = 55.784.\n",
      "[0478] test = 372.359, test_dummy = 35.730, train = 29.791, val = 54.663.\n",
      "[0479] test = 367.837, test_dummy = 35.730, train = 29.871, val = 52.800.\n",
      "[0480] test = 371.382, test_dummy = 35.730, train = 29.939, val = 53.494.\n",
      "[0481] test = 374.362, test_dummy = 35.730, train = 29.613, val = 58.656.\n",
      "[0482] test = 372.438, test_dummy = 35.730, train = 29.651, val = 56.881.\n",
      "[0483] test = 355.994, test_dummy = 35.730, train = 29.643, val = 50.017.\n",
      "[0484] test = 374.406, test_dummy = 35.730, train = 29.684, val = 55.732.\n",
      "[0485] test = 359.037, test_dummy = 35.730, train = 29.622, val = 50.978.\n",
      "[0486] test = 363.309, test_dummy = 35.730, train = 29.959, val = 52.910.\n",
      "[0487] test = 361.058, test_dummy = 35.730, train = 29.539, val = 51.818.\n",
      "[0488] test = 368.212, test_dummy = 35.730, train = 29.720, val = 55.075.\n",
      "[0489] test = 374.771, test_dummy = 35.730, train = 29.828, val = 56.887.\n",
      "[0490] test = 380.248, test_dummy = 35.730, train = 29.484, val = 59.060.\n",
      "[0491] test = 372.520, test_dummy = 35.730, train = 29.700, val = 54.682.\n",
      "[0492] test = 373.868, test_dummy = 35.730, train = 29.566, val = 54.563.\n",
      "[0493] test = 360.604, test_dummy = 35.730, train = 29.671, val = 50.114.\n",
      "[0494] test = 377.908, test_dummy = 35.730, train = 29.566, val = 55.496.\n",
      "[0495] test = 363.467, test_dummy = 35.730, train = 29.563, val = 50.843.\n",
      "[0496] test = 367.565, test_dummy = 35.730, train = 29.766, val = 52.226.\n",
      "[0497] test = 367.062, test_dummy = 35.730, train = 29.539, val = 51.733.\n",
      "[0498] test = 384.233, test_dummy = 35.730, train = 30.042, val = 57.472.\n",
      "[0499] test = 365.078, test_dummy = 35.730, train = 29.493, val = 51.848.\n",
      "[0500] test = 373.146, test_dummy = 35.730, train = 29.459, val = 54.736.\n",
      "[0501] test = 375.958, test_dummy = 35.730, train = 29.524, val = 56.303.\n",
      "[0502] test = 369.599, test_dummy = 35.730, train = 29.576, val = 52.413.\n",
      "[0503] test = 379.216, test_dummy = 35.730, train = 29.882, val = 55.490.\n",
      "[0504] test = 363.867, test_dummy = 35.730, train = 29.379, val = 50.296.\n",
      "[0505] test = 380.369, test_dummy = 35.730, train = 29.812, val = 55.014.\n",
      "[0506] test = 375.691, test_dummy = 35.730, train = 29.800, val = 54.367.\n",
      "[0507] test = 375.864, test_dummy = 35.730, train = 29.564, val = 54.141.\n",
      "[0508] test = 373.907, test_dummy = 35.730, train = 29.791, val = 54.974.\n",
      "[0509] test = 374.470, test_dummy = 35.730, train = 29.380, val = 53.453.\n",
      "[0510] test = 378.639, test_dummy = 35.730, train = 29.455, val = 56.438.\n",
      "[0511] test = 377.582, test_dummy = 35.730, train = 29.414, val = 56.700.\n",
      "[0512] test = 377.674, test_dummy = 35.730, train = 29.448, val = 57.294.\n",
      "[0513] test = 371.883, test_dummy = 35.730, train = 29.465, val = 54.676.\n",
      "[0514] test = 372.434, test_dummy = 35.730, train = 29.466, val = 54.522.\n",
      "[0515] test = 366.034, test_dummy = 35.730, train = 29.440, val = 52.611.\n",
      "[0516] test = 375.925, test_dummy = 35.730, train = 29.418, val = 57.643.\n",
      "[0517] test = 355.395, test_dummy = 35.730, train = 29.700, val = 49.896.\n",
      "[0518] test = 364.461, test_dummy = 35.730, train = 30.583, val = 55.189.\n",
      "[0519] test = 381.713, test_dummy = 35.730, train = 29.303, val = 59.667.\n",
      "[0520] test = 371.051, test_dummy = 35.730, train = 29.360, val = 54.418.\n",
      "[0521] test = 367.493, test_dummy = 35.730, train = 29.302, val = 53.237.\n",
      "[0522] test = 361.523, test_dummy = 35.730, train = 29.414, val = 51.538.\n",
      "[0523] test = 369.031, test_dummy = 35.730, train = 29.381, val = 53.189.\n",
      "[0524] test = 377.213, test_dummy = 35.730, train = 29.480, val = 56.175.\n",
      "[0525] test = 368.630, test_dummy = 35.730, train = 29.522, val = 53.166.\n",
      "[0526] test = 353.934, test_dummy = 35.730, train = 31.210, val = 49.682.\n",
      "[0527] test = 379.787, test_dummy = 35.730, train = 30.462, val = 55.472.\n",
      "[0528] test = 379.399, test_dummy = 35.730, train = 29.421, val = 55.681.\n",
      "[0529] test = 387.989, test_dummy = 35.730, train = 29.618, val = 58.761.\n",
      "[0530] test = 368.197, test_dummy = 35.730, train = 29.342, val = 52.560.\n",
      "[0531] test = 366.359, test_dummy = 35.730, train = 29.260, val = 52.062.\n",
      "[0532] test = 375.359, test_dummy = 35.730, train = 29.436, val = 56.331.\n",
      "[0533] test = 372.582, test_dummy = 35.730, train = 29.360, val = 54.302.\n",
      "[0534] test = 369.395, test_dummy = 35.730, train = 29.194, val = 52.942.\n",
      "[0535] test = 370.725, test_dummy = 35.730, train = 29.409, val = 51.976.\n",
      "[0536] test = 370.811, test_dummy = 35.730, train = 29.214, val = 52.883.\n",
      "[0537] test = 382.714, test_dummy = 35.730, train = 29.178, val = 59.389.\n",
      "[0538] test = 375.571, test_dummy = 35.730, train = 29.437, val = 54.755.\n",
      "[0539] test = 367.881, test_dummy = 35.730, train = 29.240, val = 51.878.\n",
      "[0540] test = 378.399, test_dummy = 35.730, train = 29.912, val = 55.105.\n",
      "[0541] test = 372.552, test_dummy = 35.730, train = 29.176, val = 53.876.\n",
      "[0542] test = 372.805, test_dummy = 35.730, train = 29.178, val = 52.991.\n",
      "[0543] test = 375.291, test_dummy = 35.730, train = 29.131, val = 55.268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0544] test = 378.023, test_dummy = 35.730, train = 29.202, val = 56.511.\n",
      "[0545] test = 367.745, test_dummy = 35.730, train = 29.160, val = 52.574.\n",
      "[0546] test = 378.094, test_dummy = 35.730, train = 29.162, val = 56.650.\n",
      "[0547] test = 371.111, test_dummy = 35.730, train = 29.227, val = 54.411.\n",
      "[0548] test = 365.160, test_dummy = 35.730, train = 29.083, val = 52.209.\n",
      "[0549] test = 369.549, test_dummy = 35.730, train = 29.489, val = 53.692.\n",
      "[0550] test = 370.718, test_dummy = 35.730, train = 29.101, val = 54.293.\n",
      "[0551] test = 372.269, test_dummy = 35.730, train = 29.088, val = 54.877.\n",
      "[0552] test = 371.256, test_dummy = 35.730, train = 29.206, val = 53.719.\n",
      "[0553] test = 382.252, test_dummy = 35.730, train = 29.178, val = 61.244.\n",
      "[0554] test = 372.386, test_dummy = 35.730, train = 29.199, val = 56.124.\n",
      "[0555] test = 369.879, test_dummy = 35.730, train = 28.999, val = 54.039.\n",
      "[0556] test = 373.163, test_dummy = 35.730, train = 28.990, val = 55.084.\n",
      "[0557] test = 373.139, test_dummy = 35.730, train = 28.996, val = 54.565.\n",
      "[0558] test = 375.763, test_dummy = 35.730, train = 28.956, val = 55.029.\n",
      "[0559] test = 361.832, test_dummy = 35.730, train = 29.021, val = 51.788.\n",
      "[0560] test = 363.714, test_dummy = 35.730, train = 29.207, val = 51.857.\n",
      "[0561] test = 364.999, test_dummy = 35.730, train = 29.197, val = 54.170.\n",
      "[0562] test = 367.514, test_dummy = 35.730, train = 29.263, val = 56.070.\n",
      "[0563] test = 354.376, test_dummy = 35.730, train = 29.075, val = 50.452.\n",
      "[0564] test = 370.813, test_dummy = 35.730, train = 29.279, val = 56.611.\n",
      "[0565] test = 362.616, test_dummy = 35.730, train = 28.994, val = 52.558.\n",
      "[0566] test = 364.264, test_dummy = 35.730, train = 29.111, val = 53.922.\n",
      "[0567] test = 358.196, test_dummy = 35.730, train = 28.954, val = 51.947.\n",
      "[0568] test = 359.654, test_dummy = 35.730, train = 28.960, val = 52.537.\n",
      "[0569] test = 363.175, test_dummy = 35.730, train = 29.230, val = 55.569.\n",
      "[0570] test = 351.393, test_dummy = 35.730, train = 29.211, val = 51.838.\n",
      "[0571] test = 359.170, test_dummy = 35.730, train = 28.913, val = 54.224.\n",
      "[0572] test = 368.713, test_dummy = 35.730, train = 28.940, val = 56.534.\n",
      "[0573] test = 367.110, test_dummy = 35.730, train = 28.867, val = 54.436.\n",
      "[0574] test = 359.312, test_dummy = 35.730, train = 29.045, val = 52.528.\n",
      "[0575] test = 370.579, test_dummy = 35.730, train = 29.049, val = 56.903.\n",
      "[0576] test = 357.078, test_dummy = 35.730, train = 29.006, val = 52.383.\n",
      "[0577] test = 363.864, test_dummy = 35.730, train = 28.963, val = 55.101.\n",
      "[0578] test = 367.729, test_dummy = 35.730, train = 29.308, val = 54.538.\n",
      "[0579] test = 355.750, test_dummy = 35.730, train = 28.977, val = 51.772.\n",
      "[0580] test = 373.903, test_dummy = 35.730, train = 29.279, val = 59.021.\n",
      "[0581] test = 364.145, test_dummy = 35.730, train = 29.313, val = 54.693.\n",
      "[0582] test = 361.369, test_dummy = 35.730, train = 28.934, val = 54.505.\n",
      "[0583] test = 360.758, test_dummy = 35.730, train = 28.823, val = 55.789.\n",
      "[0584] test = 356.568, test_dummy = 35.730, train = 29.345, val = 52.796.\n",
      "[0585] test = 360.926, test_dummy = 35.730, train = 28.829, val = 54.635.\n",
      "[0586] test = 357.884, test_dummy = 35.730, train = 29.018, val = 52.334.\n",
      "[0587] test = 357.505, test_dummy = 35.730, train = 28.842, val = 51.850.\n",
      "[0588] test = 365.649, test_dummy = 35.730, train = 28.860, val = 56.238.\n",
      "[0589] test = 358.297, test_dummy = 35.730, train = 28.887, val = 53.103.\n",
      "[0590] test = 356.472, test_dummy = 35.730, train = 29.213, val = 52.115.\n",
      "[0591] test = 369.115, test_dummy = 35.730, train = 28.827, val = 56.969.\n",
      "[0592] test = 363.007, test_dummy = 35.730, train = 28.821, val = 55.414.\n",
      "[0593] test = 361.330, test_dummy = 35.730, train = 28.792, val = 54.698.\n",
      "[0594] test = 360.246, test_dummy = 35.730, train = 28.731, val = 53.796.\n",
      "[0595] test = 366.671, test_dummy = 35.730, train = 28.819, val = 56.610.\n",
      "[0596] test = 362.877, test_dummy = 35.730, train = 28.714, val = 55.993.\n",
      "[0597] test = 360.822, test_dummy = 35.730, train = 28.851, val = 54.092.\n",
      "[0598] test = 360.030, test_dummy = 35.730, train = 28.726, val = 54.535.\n",
      "[0599] test = 360.626, test_dummy = 35.730, train = 28.911, val = 53.861.\n"
     ]
    }
   ],
   "source": [
    "def print_np_arr(x):\n",
    "    return np.array_repr(x).replace('\\n', '')\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "class Monitor(Callback):\n",
    "\n",
    "    def __init__(self, inputs):\n",
    "        self.inputs = inputs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "        # print('\\n\\n')\n",
    "        # print('_' * 80)\n",
    "\n",
    "        # TODO: make it with pandas and better.\n",
    "        predictions = self.model.predict(self.inputs)\n",
    "        # TODO: should be the mean_sigma of std_sigma only\n",
    "        pred_sigmas = [z_score_inv(pred, mean, std) for pred in predictions.flatten()]\n",
    "        true_sigmas = [z_score_inv(true, mean, std) for true in y_test.flatten()]\n",
    "        dummy_sigmas = [z_score_inv(dummy, mean, std) for dummy in np.roll(y_test.flatten(), shift=1)]\n",
    "\n",
    "        #if 'DISPLAY' not in os.environ:\n",
    "        #    plt.clf()\n",
    "        #    plt.plot(true_sigmas, color='blue')\n",
    "        #    plt.plot(pred_sigmas, color='lime')\n",
    "        #    plt.pause(0.001)\n",
    "        #    plt.show()\n",
    "\n",
    "        test_mape = mean_absolute_percentage_error(np.array(true_sigmas), np.array(pred_sigmas))\n",
    "        dummy_mape = mean_absolute_percentage_error(np.array(true_sigmas), np.array(dummy_sigmas))\n",
    "        print('[{0}] test = {1:.3f}, test_dummy = {2:.3f}, '\n",
    "              'train = {3:.3f}, val = {4:.3f}.'.format(str(epoch).zfill(4), test_mape, dummy_mape,\n",
    "                                                       logs['loss'], logs['val_loss']))\n",
    "        \n",
    "        logs['MAPE']=test_mape\n",
    "        # num_values_to_predict = 10\n",
    "        # r_train_idx = randint(a=0, b=len(x_train) - num_values_to_predict)\n",
    "        # print('pred train  =',\n",
    "        #       print_np_arr(self.model.predict(x_train[r_train_idx:r_train_idx + num_values_to_predict]).flatten()))\n",
    "        # print('truth train =', print_np_arr(y_train[r_train_idx:r_train_idx + num_values_to_predict].flatten()))\n",
    "        # r_test_idx = randint(a=0, b=len(x_test) - num_values_to_predict)\n",
    "        # print('pred  test  =',\n",
    "        #       print_np_arr(self.model.predict(x_test[r_test_idx:r_test_idx + num_values_to_predict]).flatten()))\n",
    "        # print('truth test  =', print_np_arr(y_test[r_test_idx:r_test_idx + num_values_to_predict].flatten()))\n",
    "        # print('_' * 80)\n",
    "        # print('\\n')\n",
    "\n",
    "\n",
    "m = Sequential()\n",
    "m.add(LSTM(32, input_shape=(LSTM_WINDOW_SIZE, INPUT_SIZE)))\n",
    "# m.add(Dropout(0.1))\n",
    "m.add(Dense(16, activation='sigmoid'))\n",
    "# m.add(Dropout(0.1))\n",
    "m.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "# PAPER: with mean absolute percent error (MAPE) as the objective loss function\n",
    "# PAPER: The model is trained by the 'Adam' method\n",
    "\n",
    "def sigma_loss(y_true, y_pred):\n",
    "    real_y_true = y_true * std + mean\n",
    "    real_y_pred = y_pred * std + mean\n",
    "    return K.mean(K.abs(real_y_true - real_y_pred) / real_y_true) * 100\n",
    "\n",
    "\n",
    "m.compile(optimizer=Adam(lr=0.0001), loss=sigma_loss)  # mape\n",
    "m.summary()\n",
    "\n",
    "for until_predictor_id in range(6, len(PREDICTORS)):\n",
    "\n",
    "    try:\n",
    "        print('Now we have {}/{} predictors.'.format(until_predictor_id + 1, len(PREDICTORS)))\n",
    "        mask_train = np.zeros_like(x_train)\n",
    "        mask_test = np.zeros_like(x_test)\n",
    "\n",
    "        mask_train[:, :, 0:until_predictor_id + 1] = 1.0\n",
    "        mask_test[:, :, 0:until_predictor_id + 1] = 1.0\n",
    "\n",
    "        x_train_masked = x_train * mask_train\n",
    "        x_test_masked = x_test * mask_test\n",
    "\n",
    "        # PAPER: with 32 examples in a batch\n",
    "        # PAPER:  This can be achieved after roughly 600 epochs.\n",
    "        monitor = Monitor(inputs=x_test_masked)\n",
    "        model = m.fit(x_train_masked, y_train,\n",
    "                      validation_split=0.2,\n",
    "                      shuffle=True,\n",
    "                      batch_size=32,\n",
    "                      epochs=600,\n",
    "                      verbose=0,\n",
    "                      callbacks=[monitor])\n",
    "\n",
    "        # print('Learning rate was {}'.format(K.get_value(m.optimizer.lr)))\n",
    "        # K.set_value(m.optimizer.lr, K.get_value(m.optimizer.lr) * 0.5)\n",
    "        # print('Learning rate is now {}'.format(K.get_value(m.optimizer.lr)))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('Received KeyboardInterrupt. Going to add the next predictor.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbc5d8a4128>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history['MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
